{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "338695f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "df = pd.read_excel('data/sample_finish.xlsx')\n",
    "df_id = df['ID1'].tolist()\n",
    "# random.seed(520)\n",
    "random_id=random.sample(df_id,1)[0]\n",
    "random_row=df[df['ID1'] ==random_id]\n",
    "random_row=eval(random_row['TEXT2_padded'].iloc[0])\n",
    "df['TEXT1_padded'] = [eval(df['TEXT1_padded'].iloc[i]) for i in range(len(df['TEXT1_padded']))]\n",
    "df['TEXT2_padded'] = [eval(df['TEXT2_padded'].iloc[i]) for i in range(len(df['TEXT2_padded']))]\n",
    "test2_row = np.vstack((df['TEXT1_padded'].tolist(),df['TEXT2_padded'].tolist()))\n",
    "answer_id = df['ID1'].tolist()+df['ID2'].tolist()\n",
    "random_row = np.array(random_row)\n",
    "random_row = np.reshape(random_row,(-1,115))\n",
    "random_row=np.tile(random_row,(test2_row.shape[0],1))\n",
    "loaded_model = keras.models.load_model(\"siamese_model.h5\")\n",
    "X1 = keras.preprocessing.sequence.pad_sequences(random_row, padding='post')\n",
    "X2 = keras.preprocessing.sequence.pad_sequences(test2_row, padding='post')\n",
    "data1=loaded_model.predict([X1,X2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "69a59fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "df = pd.read_excel('data/sample_finish.xlsx')\n",
    "df_id = df['ID1'].tolist()\n",
    "# random.seed(520)\n",
    "random_id=random.sample(df_id,1)[0]\n",
    "random_row=df[df['ID1'] ==random_id]\n",
    "random_row=eval(random_row['TEXT2_padded'].iloc[0])\n",
    "df['TEXT1_padded'] = [eval(df['TEXT1_padded'].iloc[i]) for i in range(len(df['TEXT1_padded']))]\n",
    "df['TEXT2_padded'] = [eval(df['TEXT2_padded'].iloc[i]) for i in range(len(df['TEXT2_padded']))]\n",
    "test2_row = np.vstack((df['TEXT1_padded'].tolist(),df['TEXT2_padded'].tolist()))\n",
    "answer_id = df['ID1'].tolist()+df['ID2'].tolist()\n",
    "random_row = np.array(random_row)\n",
    "random_row = np.reshape(random_row,(-1,115))\n",
    "random_row=np.tile(random_row,(test2_row.shape[0],1))\n",
    "loaded_model = keras.models.load_model(\"siamese_model.h5\")\n",
    "X1 = keras.preprocessing.sequence.pad_sequences(random_row, padding='post')\n",
    "X2 = keras.preprocessing.sequence.pad_sequences(test2_row, padding='post')\n",
    "data2=loaded_model.predict([X1,X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "eda9bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1515554e-05],\n",
       "       [5.1444513e-05],\n",
       "       [5.3925447e-05],\n",
       "       ...,\n",
       "       [5.8774036e-05],\n",
       "       [3.7375022e-02],\n",
       "       [1.8414977e-03]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "36f19c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3310,  562, 1287, 3388, 3113, 3402, 3092, 3450, 2499,  176, 3148,\n",
       "       3966, 2415, 2418,  901, 2103,    6,  697, 1459, 1185], dtype=int64)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices = np.argsort(data1.flatten())[-20:][::-1]\n",
    "max_values = np.sort(data1.flatten())[-20:][::-1]\n",
    "max_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f63d9e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3310, 1287,  562, 3388, 3113, 3092, 3402, 3450, 2499,  176, 3966,\n",
       "       3148, 2415, 2418,    6,  901,  697, 2103, 1459, 1185], dtype=int64)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices = np.argsort(data2.flatten())[-20:][::-1]\n",
    "max_values = np.sort(data2.flatten())[-20:][::-1]\n",
    "max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "74101294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28333"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_id[3310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e6bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yourpath/0/pic0.png\n",
      "yourpath/0/pic1.png\n",
      "yourpath/0/pic2.png\n",
      "yourpath/0/pic3.png\n",
      "yourpath/0/pic4.png\n",
      "yourpath/0/pic5.png\n",
      "yourpath/1/pic0.png\n",
      "yourpath/1/pic1.png\n",
      "yourpath/1/pic2.png\n",
      "yourpath/1/pic3.png\n",
      "yourpath/1/pic4.png\n",
      "yourpath/1/pic5.png\n",
      "yourpath/2/pic0.png\n",
      "yourpath/2/pic1.png\n",
      "yourpath/2/pic2.png\n",
      "yourpath/2/pic3.png\n",
      "yourpath/2/pic4.png\n",
      "yourpath/2/pic5.png\n",
      "yourpath/3/pic0.png\n",
      "yourpath/3/pic1.png\n",
      "yourpath/3/pic2.png\n",
      "yourpath/3/pic3.png\n",
      "yourpath/3/pic4.png\n",
      "yourpath/3/pic5.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tmp_list=[]\n",
    "label =[]\n",
    "for i in range(4):\n",
    "\tfor j in range(6):\n",
    "\t\tpath='yourpath/'+str(i)+'/pic'+str(j)+'.png'\n",
    "\t\tprint(path)\n",
    "\t\ttmp_list.append(path)\n",
    "\t\tlabel.append(i)\n",
    "\n",
    "\n",
    "tmp_list=np.array(tmp_list).transpose()\n",
    "label=np.array(label).transpose()\n",
    "\n",
    "sample = np.vstack((tmp_list,label)).transpose()\n",
    "\n",
    "# sample=pd.DataFrame(sample,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad5fd1cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['yourpath/0/pic0.png', '0'],\n",
       "       ['yourpath/0/pic1.png', '0'],\n",
       "       ['yourpath/0/pic2.png', '0'],\n",
       "       ['yourpath/0/pic3.png', '0'],\n",
       "       ['yourpath/0/pic4.png', '0'],\n",
       "       ['yourpath/0/pic5.png', '0'],\n",
       "       ['yourpath/1/pic0.png', '1'],\n",
       "       ['yourpath/1/pic1.png', '1'],\n",
       "       ['yourpath/1/pic2.png', '1'],\n",
       "       ['yourpath/1/pic3.png', '1'],\n",
       "       ['yourpath/1/pic4.png', '1'],\n",
       "       ['yourpath/1/pic5.png', '1'],\n",
       "       ['yourpath/2/pic0.png', '2'],\n",
       "       ['yourpath/2/pic1.png', '2'],\n",
       "       ['yourpath/2/pic2.png', '2'],\n",
       "       ['yourpath/2/pic3.png', '2'],\n",
       "       ['yourpath/2/pic4.png', '2'],\n",
       "       ['yourpath/2/pic5.png', '2'],\n",
       "       ['yourpath/3/pic0.png', '3'],\n",
       "       ['yourpath/3/pic1.png', '3'],\n",
       "       ['yourpath/3/pic2.png', '3'],\n",
       "       ['yourpath/3/pic3.png', '3'],\n",
       "       ['yourpath/3/pic4.png', '3'],\n",
       "       ['yourpath/3/pic5.png', '3']], dtype='<U19')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3019422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "def get_num(s):\n",
    "    text=s\n",
    "    number = None\n",
    "    matches = re.findall(r'\\d+',text)\n",
    "    if len(matches) > 0:\n",
    "        number=int(matches[0])\n",
    "    return number\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('data/附件1.csv')\n",
    "df2 = pd.read_csv('data/附件2.csv')\n",
    "\n",
    "id_df1= df1['id'].tolist()\n",
    "id_df2 = df2['questionID'].tolist()\n",
    "cnt = 0\n",
    "for i in id_df2:\n",
    "    if i not in id_df1:\n",
    "        cnt+=1\n",
    "print(cnt)\n",
    "df2_repeat=df2[df2['duplicates'].notnull()]\n",
    "sep_quesid=df2_repeat['questionID'].tolist()\n",
    "seq_reid_str=df2_repeat['duplicates'].tolist()\n",
    "seq_reid=[]\n",
    "for s in seq_reid_str:\n",
    "    num=get_num(s)\n",
    "    seq_reid.append(num)\n",
    "com_id = np.column_stack((sep_quesid,seq_reid))\n",
    "for i in sep_quesid:\n",
    "    id_df1.remove(i)\n",
    "for i in seq_reid:\n",
    "    if i in id_df1:\n",
    "        id_df1.remove(i)\n",
    "com_id2=[]\n",
    "for i in range(2000-len(com_id)):\n",
    "    random.seed(i**3+50+i**2)\n",
    "    random_numbers = random.sample(id_df1, 2)\n",
    "    com_id2.append(random_numbers)\n",
    "com_id2=np.array(com_id2)\n",
    "com_id_new = np.vstack((com_id,com_id2))\n",
    "label=[1]*len(com_id)+[0]*len(com_id2)\n",
    "label= np.array(label)\n",
    "label=label.reshape(-1,1)\n",
    "sample = np.hstack((com_id_new,label))\n",
    "random.seed(521)\n",
    "indices = np.arange(sample.shape[0])\n",
    "random.shuffle(indices)\n",
    "sample=sample[indices]\n",
    "\n",
    "# 创建一个DataFrame，可以根据需要指定列名\n",
    "df = pd.DataFrame(sample, columns=['ID1', 'ID2', 'label'])\n",
    "# df.to_excel('data/sample.xlsx',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684bdbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 89938,  35590,      1],\n",
       "       [ 50415,  25518,      1],\n",
       "       [ 17537,   7839,      1],\n",
       "       ...,\n",
       "       [112580,  44798,      0],\n",
       "       [ 63022,  62860,      1],\n",
       "       [ 52975,  48925,      1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter] *",
   "language": "python",
   "name": "conda-env-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
